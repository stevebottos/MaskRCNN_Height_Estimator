{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"rcnn-nb.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P40G3CMsOLS6","colab_type":"code","outputId":"1c9ebae8-b3a0-401d-be2f-1bce7c8dba0e","executionInfo":{"status":"error","timestamp":1576096724516,"user_tz":480,"elapsed":1191,"user":{"displayName":"Steve Bottos","photoUrl":"","userId":"00089604893724931155"}},"colab":{"base_uri":"https://localhost:8080/","height":680}},"source":["!nvidia-smi\n","############################################################\n","#  Program Settings\n","############################################################\n","specific_model = 'full-pallet'  # 'product-on-pallet' or 'full-pallet'\n","recent_weights = '/content/drive/My Drive/Colab Notebooks/mrcnn/mask_rcnn_coco.h5' # '/content/drive/My Drive/Colab Notebooks/full-pallet/logs/full-pallet20191210T0145/mask_rcnn_full-pallet_0039.h5'\n","setting = 'test' \n","train_with = 'all' # heads or all\n","allow_augmentation = True\n","\n","\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/mcrnn/')\n","import os\n","import json\n","from keras.models import load_model\n","import numpy as np\n","import skimage.draw\n","import matplotlib.pyplot as plt\n","from mrcnn.config import Config\n","from mrcnn import visualize\n","from mrcnn import model as modellib, utils\n","from mrcnn.visualize import display_images\n","from mrcnn.model import log\n","# %tensorflow_version 1.x\n","\n","############################################################\n","#  Configurations\n","############################################################\n","\n","class ProductsConfig(Config):\n","    \"\"\"Configuration for training on the toy  dataset.\n","    Derives from the base Config class and overrides some values.\n","    \"\"\"\n","    # Give the configuration a recognizable name\n","    NAME = specific_model\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1 # Batch size to train on\n","    # Number of classes (including background)\n","    NUM_CLASSES = 1 + 1  # Background + object of interest\n","    STEPS_PER_EPOCH = len(os.listdir('/content/drive/My Drive/Colab Notebooks/'+specific_model+'/select_images_cnn/train/'))\n","    print(STEPS_PER_EPOCH)\n","    DETECTION_MIN_CONFIDENCE = 0.965\n","\n","    if specific_model != 'product-on-pallet': \n","        # Some stuff to speed it up, comment out if necessary\n","        MAX_GT_INSTANCES = 100\n","        IMAGE_MIN_DIM = 512\n","        IMAGE_MAX_DIM = 512\n","        TRAIN_ROIS_PER_IMAGE = 200\n","        # BACKBONE = \"resnet50\"\n","        # Resnet 50 is quicker but less accurate, might be just fine though\n","\n","\n","############################################################\n","#  Dataset\n","############################################################\n","\n","class ProductsDataset(utils.Dataset):\n","\n","    def load_images(self, subset):\n","        print('subset =', subset)\n","        assert subset in ['train', 'val', 'test']\n","        # Add classes. We have only one class to add.\n","        self.add_class(specific_model, 1, specific_model)\n","\n","        if (subset == 'train') or (subset == 'val'):\n","            # Path to the json that contains the metadata\n","            f = open('/content/drive/My Drive/Colab Notebooks/'+specific_model+'/select_images_cnn/'+subset+'data.json')\n","            jsondat = json.load(f)\n","\n","            # All of the annotations for all of the images\n","            annotations = list(jsondat.values())  # don't need the dict keys\n","\n","            # The annotate tool saves images in the JSON even if they don't have any\n","            # annotations. Skip unannotated images.\n","            annotations = [a for a in annotations if a['regions']]\n","\n","            # Add images\n","            n = 1\n","            for a in annotations:\n","                # Get the x, y coordinaets of points of the polygons that make up\n","                # the outline of each object instance. These are stores in the\n","                # shape_attributes (see json format above)\n","                # The if condition is needed to support VIA versions 1.x and 2.x.\n","\n","\n","                # problem with these ones apparently, no idea what - images and annotations look good...\n","                issues = ['SamsClub6235_110119_080838_872812.jpg', \n","                          'SamsClub6235_110119_083325_616724.jpg', \n","                          'SamsClub6235_110119_075403_627780.jpg',\n","                          'SamsClub6235_110119_075522_618224.jpg']\n","\n","                if a['filename'] in issues:\n","                  continue\n","\n","                if type(a['regions']) is dict:\n","                    polygons = [r['shape_attributes'] for r in a['regions'].values()]\n","                else:\n","                    polygons = [r['shape_attributes'] for r in a['regions']]\n","\n","                # load_mask() needs the image size to convert polygons to masks.\n","                # Unfortunately, VIA doesn't include it in JSON, so we must read\n","                # the image. This is only managable since the dataset is tiny.\n","                image_path = '/content/drive/My Drive/Colab Notebooks/'+specific_model+'/select_images_cnn/'+subset+'/'+a['filename']\n","                image = skimage.io.imread(image_path)\n","                print(n)\n","                n += 1\n","                height, width = image.shape[:2]\n","                \n","                self.add_image(\n","                    specific_model,\n","                    image_id=a['filename'],  # use file name as a unique image id\n","                    path=image_path,\n","                    width=width, height=height,\n","                    polygons=polygons)\n","          \n","        elif subset == 'test':\n","            path = '/content/drive/My Drive/Colab Notebooks/'+specific_model+'/select_images_cnn/test/'\n","            annotations = os.listdir(path)\n","            print(path)\n","            print(annotations)\n","            for a in annotations:\n","                image_path = path + a\n","                image = skimage.io.imread(image_path)\n","                height, width = image.shape[:2]\n","\n","                self.add_image(\n","                    specific_model,\n","                    image_id=a,  \n","                    path=image_path,\n","                    width=width, height=height,\n","                    polygons=None)\n","              \n","    def load_mask(self, image_id):\n","        \"\"\"Generate instance masks for an image.\n","       Returns:\n","        masks: A bool array of shape [height, width, instance count] with\n","            one mask per instance.\n","        class_ids: a 1D array of class IDs of the instance masks.\n","        \"\"\"\n","\n","        # If not a balloon dataset image, delegate to parent class.\n","        image_info = self.image_info[image_id]\n","        if image_info[\"source\"] != specific_model:\n","            return super(self.__class__, self).load_mask(image_id)\n","\n","        # Convert polygons to a bitmap mask of shape [height, width, instance_count]\n","        info = self.image_info[image_id]\n","        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n","                        dtype=np.uint8)\n","        for i, p in enumerate(info[\"polygons\"]):\n","            # Get indexes of pixels inside the polygon and set them to 1\n","            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n","            mask[rr, cc, i] = 1\n","\n","        # Return mask, and array of class IDs of each instance. Since we have\n","        # one class ID only, we return an array of 1s\n","        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n","\n","    def image_reference(self, image_id):\n","        \"\"\"Return the path of the image.\"\"\"\n","        info = self.image_info[image_id]\n","        if info[\"source\"] == specific_model:\n","            return info[\"path\"]\n","\n","\n","def train(model, num_epochs):\n","\n","    # Image Augmentation if allow_augmentation = True\n","    # Right/Left flip 50% of the time\n","    augmentation = None\n","    print(allow_augmentation)\n","    if allow_augmentation:\n","      import imgaug.augmenters\n","      augmentation = imgaug.augmenters.Fliplr(0.5)\n","\n","    # Training dataset.\n","    print('Making train set')\n","    dataset_train = ProductsDataset()\n","    dataset_train.load_images(\"train\")\n","    dataset_train.prepare()\n","\n","    # Validation dataset\n","    print('Making validation set')\n","    dataset_val = ProductsDataset()\n","    dataset_val.load_images(\"val\")\n","    dataset_val.prepare()\n","\n","    # *** This training schedule is an example. Update to your needs ***\n","    # Since we're using a very small dataset, and starting from\n","    # COCO trained weights, we don't need to train too long. Also,\n","    # no need to train all layers, just the heads should do it.\n","    print(\"Training network heads\")\n","    model.train(dataset_train, dataset_val,\n","                learning_rate=config.LEARNING_RATE,\n","                epochs=num_epochs,\n","                augmentation = augmentation,\n","                layers = train_with) # previously augmentation=None, layers='heads'\n","\n","\n","############################################################\n","#  Model stuff\n","############################################################\n","\n","if setting == 'train':\n","    # Path to trained weights file\n","    WEIGHTS_PATH = recent_weights\n","    config = ProductsConfig()\n","    model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='/content/drive/My Drive/Colab Notebooks/'+specific_model+'/logs')\n","    # pre-trained weights to start with\n","    weights_path = WEIGHTS_PATH\n","    model.load_weights(weights_path, by_name=True, exclude=[\n","        \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","        \"mrcnn_bbox\", \"mrcnn_mask\"])\n","\n","    # print('Training...')\n","    train(model, num_epochs=200)\n","\n","elif setting == 'test':\n","    def get_ax(rows=1, cols=1, size=16):\n","      #  Adjust the size attribute to control how big to render images\n","      fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","      return fig, ax\n","    \n","    config = ProductsConfig()\n","    model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='/content/drive/My Drive/Colab Notebooks/'+specific_model+'/logs')\n","    weights_path = model.find_last()\n","    print(weights_path)\n","    model.load_weights(weights_path, by_name=True)\n","\n","    path = '/content/drive/My Drive/Colab Notebooks/'+specific_model+'/select_images_cnn/test/'\n","\n","    for f in os.listdir(path):\n","        image = skimage.io.imread(path + f)\n","        results = model.detect([image], verbose=1)\n","\n","        # # Display results\n","        fig, ax = get_ax(1)\n","        r = results[0]\n","        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","                                    specific_model, r['scores'], ax=ax,\n","                                    title=\"Predictions\")\n","        \n","        # fig.savefig('/content/drive/My Drive/Colab Notebooks/'+specific_model+'/outputs_test/' + f)\n","        # plt.close()\n","\n","# elif setting == 'eval':\n","#     def get_ax(rows=1, cols=1, size=16):\n","#       #  Adjust the size attribute to control how big to render images\n","#       fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","#       return fig, ax\n","\n","\n","#     dataset = ProductsDataset()\n","#     dataset.load_images(subset=\"val\")\n","      \n","#     # Must call before using the dataset\n","#     dataset.prepare()\n","\n","#     # Load in the model\n","#     config = ProductsConfig()\n","#     model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='/content/drive/My Drive/Colab Notebooks/logs')\n","#     weights_path = model.find_last()\n","#     model.load_weights(weights_path, by_name=True)\n","\n","#     for f in dataset.image_ids:\n","#         image_id = f\n","#         image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","#         modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n","#         info = dataset.image_info[image_id]\n","#         # print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n","#         #                                       dataset.image_reference(image_id)))\n","\n","#         # Run object detection\n","#         results = model.detect([image], verbose=1)\n","\n","#         # Display results\n","#         # fig, ax = plt.subplots()\n","#         fig, ax = get_ax(1)\n","#         r = results[0]\n","#         visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","#                                     dataset.class_names, r['scores'], ax=ax,\n","#                                     title=\"Predictions\")\n","\n","#         # fig.savefig('/content/drive/My Drive/Colab Notebooks/outputs_val/' + info['id'])\n","#         # plt.close()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wed Dec 11 20:38:42 2019       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.36       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    34W / 250W |    267MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","383\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-ecfe4bad0364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductsConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#'/content/drive/My Drive/Colab Notebooks/'+specific_model+'/logs')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_last\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/mrcnn/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, config, model_dir)\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/mrcnn/model.py\u001b[0m in \u001b[0;36mset_log_dir\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# Directory for training logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m         self.log_dir = os.path.join(self.model_dir, \"{}{:%Y%m%dT%H%M}\".format(\n\u001b[0;32m-> 2270\u001b[0;31m             self.config.NAME.lower(), now))\n\u001b[0m\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;31m# Path to save after each epoch. Include placeholders that get filled by Keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"]}]}]}